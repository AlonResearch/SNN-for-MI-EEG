{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy9K5bJ9aB7D",
        "outputId": "717b332f-067d-4a07-dae2-0b7a633bd154"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import torch\n",
        "import torch.utils.data as da\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import scipy.io as scio\n",
        "#!pip install spikingjelly\n",
        "from spikingjelly.activation_based import ann2snn\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lAEV1BHaBp9",
        "outputId": "111b0289-9c89-4185-ce76-32259af92ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CYNshZR5ZhDy"
      },
      "outputs": [],
      "source": [
        "#Defining functions\n",
        "\n",
        "def data_loader(data, label, batch=64, shuffle=True, drop=False):\n",
        "    \"\"\"\n",
        "    Preprocess the data to fit model.\n",
        "    Feed data into data_loader.\n",
        "    input:\n",
        "        data (float): samples*length*ch (samples*ch*length).\n",
        "        label (int): samples, ie.: [0, 1, 1, 0, ..., 2].\n",
        "        batch (int): batch size\n",
        "        shuffle (bool): shuffle data before input into decoder\n",
        "        drop (bool): drop the last samples if True\n",
        "    output:\n",
        "        data loader\n",
        "    \"\"\"\n",
        "    label = torch.LongTensor(label.flatten()).to(device)\n",
        "    if data.shape[1] >= data.shape[2]:\n",
        "        data = torch.tensor(data.swapaxes(1, 2))\n",
        "    data = torch.unsqueeze(data, dim=1).type('torch.FloatTensor').to(device)\n",
        "    data = da.TensorDataset(data, label)\n",
        "    loader = da.DataLoader(dataset=data, batch_size=batch, shuffle=shuffle, drop_last=drop)\n",
        "    return loader\n",
        "\n",
        "\n",
        "def val_snn(Dec, test_loader, T=None):\n",
        "    Dec.eval().to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    if T is not None:\n",
        "        corrects = np.zeros(T)\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            if T is None:\n",
        "                outputs = Dec(inputs)\n",
        "                correct += (outputs.argmax(dim=1) == targets.to(device)).float().sum().item()\n",
        "            else:\n",
        "                for m in Dec.modules():\n",
        "                    if hasattr(m, 'reset'):\n",
        "                        m.reset()\n",
        "                for t in range(T):\n",
        "                    if t == 0:\n",
        "                        outputs = Dec(inputs)\n",
        "                    else:\n",
        "                        outputs += Dec(inputs)\n",
        "                    corrects[t] += (outputs.argmax(dim=1) == targets.to(device)).float().sum().item()\n",
        "            total += targets.shape[0]\n",
        "    return correct / total if T is None else corrects / total\n",
        "\n",
        "\n",
        "def anntosnn(ann_model, train_x, train_y, test_x, test_y, batch=64, T=None):\n",
        "    # Define data loader\n",
        "    train_loader = data_loader(train_x, train_y, batch=batch)\n",
        "    test_loader = data_loader(test_x, test_y, batch=batch)\n",
        "\n",
        "    print('---------------------------------------------')\n",
        "    print('Converting using MaxNorm')\n",
        "    model_converter = ann2snn.Converter(mode='max', dataloader=train_loader)\n",
        "    snn_model = model_converter(ann_model)\n",
        "    mode_max_accs = val_snn(snn_model, test_loader, T=T)\n",
        "\n",
        "    return mode_max_accs\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def train_ann(ann_model, train_x, train_y, test_x, test_y, ep=500, batch=64):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        train_x, test_x (float): samples*length*ch (samples*ch*length).\n",
        "        train_y, test_y (int): samples, ie.: [0, 1, 1, 0, ..., 2].\n",
        "        ep (int): total train and test epoch\n",
        "        batch (int): batch size\n",
        "    output:\n",
        "        train acc, test acc, weight_file\n",
        "    \"\"\"\n",
        "    # Define training configuration\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(ann_model.parameters(), lr=0.01)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ep)\n",
        "\n",
        "    # Define data loader\n",
        "    train_loader = data_loader(train_x, train_y, batch=batch)\n",
        "    test_loader = data_loader(test_x, test_y, batch=batch)\n",
        "\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    for epoch in range(ep):\n",
        "        # Train ANN\n",
        "        ann_model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loss = 0\n",
        "        print('\\n')\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = ann_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            print(batch_idx, len(train_loader), 'Epoch: %d | ANN: trainLoss: %.4f | trainAcc: %.4f%% (%d/%d)'\n",
        "                  % (epoch, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        train_acc.append(round(correct / total, 4))\n",
        "\n",
        "        # Test ANN\n",
        "        ann_model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "                outputs = ann_model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "                print(batch_idx, len(test_loader), 'Epoch: %d | ANN: testLoss: %.4f | testAcc: %.4f%% (%d/%d)'\n",
        "                      % (epoch, val_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "        test_acc.append(round(correct / total, 4))\n",
        "\n",
        "    train_acc = np.asarray(train_acc[-1])\n",
        "    test_acc = np.asarray(test_acc[-1])\n",
        "    return train_acc, test_acc,ann_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EC8xjyPDaM6G"
      },
      "outputs": [],
      "source": [
        "# Model 2a\n",
        "\n",
        "class LENet(nn.Module):\n",
        "    \"\"\"\n",
        "        LENet Model\n",
        "    input:\n",
        "         data shape as: batch_size*1*channel*length (64*1*22*1000) BCI IV-2a\n",
        "         batch_size：64\n",
        "         channel：22\n",
        "         length：1000\n",
        "    output:\n",
        "        classes_num\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, classes_num=4):\n",
        "        super(LENet, self).__init__()\n",
        "        self.drop_out = 0.5\n",
        "\n",
        "        self.block_TCB_1 = nn.Sequential(\n",
        "            # Temporal Convolution block kernel_size (1,64) #\n",
        "            nn.ZeroPad2d((32, 31, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 64),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "        self.block_TCB_2 = nn.Sequential(\n",
        "            # Temporal Convolution block kernel_size (1,32) #\n",
        "            nn.ZeroPad2d((16, 15, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 32),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "        self.block_TCB_3 = nn.Sequential(\n",
        "            # Temporal Convolution block kernel_size (1,16) #\n",
        "            nn.ZeroPad2d((8, 7, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 16),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "\n",
        "        self.TCB_fusion = nn.Sequential(\n",
        "            # Temporal Convolution block fusion kernel_size (1,1) #\n",
        "            nn.Conv2d(\n",
        "                in_channels=24,\n",
        "                out_channels=24,\n",
        "                kernel_size=(1, 1),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(24)\n",
        "        )\n",
        "\n",
        "        self.SCB = nn.Sequential(\n",
        "            # Spatial Convolution block kernel_size (channel,1) #\n",
        "            nn.Conv2d(\n",
        "                in_channels=24,\n",
        "                out_channels=16,\n",
        "                kernel_size=(22, 1),\n",
        "                groups=8,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "        self.FFCB = nn.Sequential(\n",
        "            # Feature Fusion Convolution block kernel_size (1,16) and (1,1) #\n",
        "            nn.ZeroPad2d((7, 8, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=16,\n",
        "                kernel_size=(1, 16),\n",
        "                groups=16,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=16,\n",
        "                kernel_size=(1, 1),\n",
        "                bias=False\n",
        "            ),  #\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "        self.CCB = nn.Sequential(\n",
        "            # Classification Convolution block kernel_size (1,1) #\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=classes_num,\n",
        "                kernel_size=(1, 1),\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.block_TCB_1(x)\n",
        "        x2 = self.block_TCB_2(x)\n",
        "        x3 = self.block_TCB_3(x)\n",
        "        x4 = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = self.TCB_fusion(x4)\n",
        "        x = self.SCB(x)\n",
        "        x = self.FFCB(x)\n",
        "        x = self.CCB(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LENet_FCL(nn.Module):\n",
        "    def __init__(self, classes_num=4):\n",
        "        super(LENet_FCL, self).__init__()\n",
        "        self.drop_out = 0.5\n",
        "        self.block_TCB_1 = nn.Sequential(\n",
        "            nn.ZeroPad2d((32, 31, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 64),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "        self.block_TCB_2 = nn.Sequential(\n",
        "            nn.ZeroPad2d((16, 15, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 32),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "        self.block_TCB_3 = nn.Sequential(\n",
        "            nn.ZeroPad2d((8, 7, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=8,\n",
        "                kernel_size=(1, 16),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "\n",
        "        self.TCB_fusion = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=24,\n",
        "                out_channels=24,\n",
        "                kernel_size=(1, 1),\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(24)\n",
        "        )\n",
        "\n",
        "        self.SCB = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=24,\n",
        "                out_channels=16,\n",
        "                kernel_size=(22, 1),\n",
        "                groups=8,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "        self.FFCB = nn.Sequential(\n",
        "            nn.ZeroPad2d((7, 8, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=16,\n",
        "                kernel_size=(1, 16),\n",
        "                groups=16,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=16,\n",
        "                kernel_size=(1, 1),\n",
        "                bias=False\n",
        "            ),  #\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "        self.FCL = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 31, classes_num)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.block_TCB_1(x)\n",
        "        x2 = self.block_TCB_2(x)\n",
        "        x3 = self.block_TCB_3(x)\n",
        "        x4 = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = self.TCB_fusion(x4)\n",
        "        x = self.SCB(x)\n",
        "        x = self.FFCB(x)\n",
        "        x = self.FCL(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "T0hmMue2aMqA",
        "outputId": "6fb20033-d2d7-41fd-e575-645347f9d428"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:73: SyntaxWarning: invalid escape sequence '\\B'\n",
            "<>:73: SyntaxWarning: invalid escape sequence '\\B'\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25280\\2934860716.py:73: SyntaxWarning: invalid escape sequence '\\B'\n",
            "  file = scio.loadmat('Datasets\\BCICIV_2a_gdf\\Derivatives\\A01T.mat')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0 3 Epoch: 0 | ANN: trainLoss: 1.9811 | trainAcc: 18.7500% (12/64)\n",
            "1 3 Epoch: 0 | ANN: trainLoss: 1.8274 | trainAcc: 22.6562% (29/128)\n",
            "2 3 Epoch: 0 | ANN: trainLoss: 1.7833 | trainAcc: 26.1628% (45/172)\n",
            "0 2 Epoch: 0 | ANN: testLoss: 1.4621 | testAcc: 28.1250% (18/64)\n",
            "1 2 Epoch: 0 | ANN: testLoss: 1.4636 | testAcc: 25.8621% (30/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 1 | ANN: trainLoss: 1.4553 | trainAcc: 31.2500% (20/64)\n",
            "1 3 Epoch: 1 | ANN: trainLoss: 1.4603 | trainAcc: 32.0312% (41/128)\n",
            "2 3 Epoch: 1 | ANN: trainLoss: 1.4898 | trainAcc: 29.6512% (51/172)\n",
            "0 2 Epoch: 1 | ANN: testLoss: 1.4229 | testAcc: 31.2500% (20/64)\n",
            "1 2 Epoch: 1 | ANN: testLoss: 1.4809 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 2 | ANN: trainLoss: 1.4242 | trainAcc: 34.3750% (22/64)\n",
            "1 3 Epoch: 2 | ANN: trainLoss: 1.3905 | trainAcc: 35.9375% (46/128)\n",
            "2 3 Epoch: 2 | ANN: trainLoss: 1.4118 | trainAcc: 31.9767% (55/172)\n",
            "0 2 Epoch: 2 | ANN: testLoss: 1.9415 | testAcc: 26.5625% (17/64)\n",
            "1 2 Epoch: 2 | ANN: testLoss: 1.8769 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 3 | ANN: trainLoss: 1.2394 | trainAcc: 42.1875% (27/64)\n",
            "1 3 Epoch: 3 | ANN: trainLoss: 1.2880 | trainAcc: 39.0625% (50/128)\n",
            "2 3 Epoch: 3 | ANN: trainLoss: 1.3038 | trainAcc: 36.6279% (63/172)\n",
            "0 2 Epoch: 3 | ANN: testLoss: 2.2538 | testAcc: 29.6875% (19/64)\n",
            "1 2 Epoch: 3 | ANN: testLoss: 2.2824 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 4 | ANN: trainLoss: 1.2354 | trainAcc: 39.0625% (25/64)\n",
            "1 3 Epoch: 4 | ANN: trainLoss: 1.2869 | trainAcc: 35.9375% (46/128)\n",
            "2 3 Epoch: 4 | ANN: trainLoss: 1.2977 | trainAcc: 35.4651% (61/172)\n",
            "0 2 Epoch: 4 | ANN: testLoss: 2.1706 | testAcc: 23.4375% (15/64)\n",
            "1 2 Epoch: 4 | ANN: testLoss: 2.1114 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 5 | ANN: trainLoss: 1.3015 | trainAcc: 34.3750% (22/64)\n",
            "1 3 Epoch: 5 | ANN: trainLoss: 1.2808 | trainAcc: 37.5000% (48/128)\n",
            "2 3 Epoch: 5 | ANN: trainLoss: 1.3347 | trainAcc: 35.4651% (61/172)\n",
            "0 2 Epoch: 5 | ANN: testLoss: 1.9898 | testAcc: 28.1250% (18/64)\n",
            "1 2 Epoch: 5 | ANN: testLoss: 1.8474 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 6 | ANN: trainLoss: 1.3066 | trainAcc: 31.2500% (20/64)\n",
            "1 3 Epoch: 6 | ANN: trainLoss: 1.2722 | trainAcc: 33.5938% (43/128)\n",
            "2 3 Epoch: 6 | ANN: trainLoss: 1.2601 | trainAcc: 35.4651% (61/172)\n",
            "0 2 Epoch: 6 | ANN: testLoss: 1.7651 | testAcc: 26.5625% (17/64)\n",
            "1 2 Epoch: 6 | ANN: testLoss: 1.7061 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 7 | ANN: trainLoss: 1.2619 | trainAcc: 34.3750% (22/64)\n",
            "1 3 Epoch: 7 | ANN: trainLoss: 1.2493 | trainAcc: 35.9375% (46/128)\n",
            "2 3 Epoch: 7 | ANN: trainLoss: 1.2187 | trainAcc: 38.9535% (67/172)\n",
            "0 2 Epoch: 7 | ANN: testLoss: 1.5167 | testAcc: 28.1250% (18/64)\n",
            "1 2 Epoch: 7 | ANN: testLoss: 1.6278 | testAcc: 26.7241% (31/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 8 | ANN: trainLoss: 1.2152 | trainAcc: 39.0625% (25/64)\n",
            "1 3 Epoch: 8 | ANN: trainLoss: 1.1715 | trainAcc: 42.1875% (54/128)\n",
            "2 3 Epoch: 8 | ANN: trainLoss: 1.2289 | trainAcc: 39.5349% (68/172)\n",
            "0 2 Epoch: 8 | ANN: testLoss: 1.7166 | testAcc: 32.8125% (21/64)\n",
            "1 2 Epoch: 8 | ANN: testLoss: 1.6501 | testAcc: 31.8966% (37/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 9 | ANN: trainLoss: 1.1684 | trainAcc: 45.3125% (29/64)\n",
            "1 3 Epoch: 9 | ANN: trainLoss: 1.1464 | trainAcc: 49.2188% (63/128)\n",
            "2 3 Epoch: 9 | ANN: trainLoss: 1.1541 | trainAcc: 46.5116% (80/172)\n",
            "0 2 Epoch: 9 | ANN: testLoss: 1.5748 | testAcc: 29.6875% (19/64)\n",
            "1 2 Epoch: 9 | ANN: testLoss: 1.7183 | testAcc: 31.0345% (36/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 10 | ANN: trainLoss: 1.1886 | trainAcc: 51.5625% (33/64)\n",
            "1 3 Epoch: 10 | ANN: trainLoss: 1.1593 | trainAcc: 50.0000% (64/128)\n",
            "2 3 Epoch: 10 | ANN: trainLoss: 1.1361 | trainAcc: 50.5814% (87/172)\n",
            "0 2 Epoch: 10 | ANN: testLoss: 1.6674 | testAcc: 29.6875% (19/64)\n",
            "1 2 Epoch: 10 | ANN: testLoss: 1.6239 | testAcc: 30.1724% (35/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 11 | ANN: trainLoss: 1.1095 | trainAcc: 48.4375% (31/64)\n",
            "1 3 Epoch: 11 | ANN: trainLoss: 1.1476 | trainAcc: 43.7500% (56/128)\n",
            "2 3 Epoch: 11 | ANN: trainLoss: 1.1539 | trainAcc: 43.0233% (74/172)\n",
            "0 2 Epoch: 11 | ANN: testLoss: 1.5572 | testAcc: 28.1250% (18/64)\n",
            "1 2 Epoch: 11 | ANN: testLoss: 1.5420 | testAcc: 30.1724% (35/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 12 | ANN: trainLoss: 1.1285 | trainAcc: 48.4375% (31/64)\n",
            "1 3 Epoch: 12 | ANN: trainLoss: 1.0846 | trainAcc: 51.5625% (66/128)\n",
            "2 3 Epoch: 12 | ANN: trainLoss: 1.1211 | trainAcc: 49.4186% (85/172)\n",
            "0 2 Epoch: 12 | ANN: testLoss: 1.4275 | testAcc: 35.9375% (23/64)\n",
            "1 2 Epoch: 12 | ANN: testLoss: 1.4268 | testAcc: 33.6207% (39/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 13 | ANN: trainLoss: 1.0631 | trainAcc: 53.1250% (34/64)\n",
            "1 3 Epoch: 13 | ANN: trainLoss: 1.0988 | trainAcc: 51.5625% (66/128)\n",
            "2 3 Epoch: 13 | ANN: trainLoss: 1.1233 | trainAcc: 48.2558% (83/172)\n",
            "0 2 Epoch: 13 | ANN: testLoss: 1.3683 | testAcc: 34.3750% (22/64)\n",
            "1 2 Epoch: 13 | ANN: testLoss: 1.3469 | testAcc: 35.3448% (41/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 14 | ANN: trainLoss: 1.0512 | trainAcc: 54.6875% (35/64)\n",
            "1 3 Epoch: 14 | ANN: trainLoss: 1.0832 | trainAcc: 52.3438% (67/128)\n",
            "2 3 Epoch: 14 | ANN: trainLoss: 1.1282 | trainAcc: 49.4186% (85/172)\n",
            "0 2 Epoch: 14 | ANN: testLoss: 1.2822 | testAcc: 37.5000% (24/64)\n",
            "1 2 Epoch: 14 | ANN: testLoss: 1.2725 | testAcc: 34.4828% (40/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 15 | ANN: trainLoss: 1.0388 | trainAcc: 54.6875% (35/64)\n",
            "1 3 Epoch: 15 | ANN: trainLoss: 1.0556 | trainAcc: 52.3438% (67/128)\n",
            "2 3 Epoch: 15 | ANN: trainLoss: 1.0888 | trainAcc: 51.7442% (89/172)\n",
            "0 2 Epoch: 15 | ANN: testLoss: 1.3383 | testAcc: 25.0000% (16/64)\n",
            "1 2 Epoch: 15 | ANN: testLoss: 1.2408 | testAcc: 35.3448% (41/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 16 | ANN: trainLoss: 1.0603 | trainAcc: 53.1250% (34/64)\n",
            "1 3 Epoch: 16 | ANN: trainLoss: 1.0396 | trainAcc: 52.3438% (67/128)\n",
            "2 3 Epoch: 16 | ANN: trainLoss: 1.0500 | trainAcc: 51.1628% (88/172)\n",
            "0 2 Epoch: 16 | ANN: testLoss: 1.3123 | testAcc: 40.6250% (26/64)\n",
            "1 2 Epoch: 16 | ANN: testLoss: 1.2636 | testAcc: 34.4828% (40/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 17 | ANN: trainLoss: 1.1136 | trainAcc: 48.4375% (31/64)\n",
            "1 3 Epoch: 17 | ANN: trainLoss: 1.0470 | trainAcc: 48.4375% (62/128)\n",
            "2 3 Epoch: 17 | ANN: trainLoss: 1.0582 | trainAcc: 50.0000% (86/172)\n",
            "0 2 Epoch: 17 | ANN: testLoss: 1.3163 | testAcc: 26.5625% (17/64)\n",
            "1 2 Epoch: 17 | ANN: testLoss: 1.2189 | testAcc: 36.2069% (42/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 18 | ANN: trainLoss: 0.9926 | trainAcc: 57.8125% (37/64)\n",
            "1 3 Epoch: 18 | ANN: trainLoss: 1.0399 | trainAcc: 55.4688% (71/128)\n",
            "2 3 Epoch: 18 | ANN: trainLoss: 1.0090 | trainAcc: 54.6512% (94/172)\n",
            "0 2 Epoch: 18 | ANN: testLoss: 1.1707 | testAcc: 37.5000% (24/64)\n",
            "1 2 Epoch: 18 | ANN: testLoss: 1.1844 | testAcc: 39.6552% (46/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 19 | ANN: trainLoss: 0.9964 | trainAcc: 45.3125% (29/64)\n",
            "1 3 Epoch: 19 | ANN: trainLoss: 1.0315 | trainAcc: 49.2188% (63/128)\n",
            "2 3 Epoch: 19 | ANN: trainLoss: 1.0475 | trainAcc: 45.9302% (79/172)\n",
            "0 2 Epoch: 19 | ANN: testLoss: 1.1217 | testAcc: 43.7500% (28/64)\n",
            "1 2 Epoch: 19 | ANN: testLoss: 1.1721 | testAcc: 40.5172% (47/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 20 | ANN: trainLoss: 1.0152 | trainAcc: 51.5625% (33/64)\n",
            "1 3 Epoch: 20 | ANN: trainLoss: 0.9907 | trainAcc: 53.9062% (69/128)\n",
            "2 3 Epoch: 20 | ANN: trainLoss: 1.0695 | trainAcc: 50.5814% (87/172)\n",
            "0 2 Epoch: 20 | ANN: testLoss: 1.1719 | testAcc: 45.3125% (29/64)\n",
            "1 2 Epoch: 20 | ANN: testLoss: 1.1594 | testAcc: 43.9655% (51/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 21 | ANN: trainLoss: 0.9370 | trainAcc: 60.9375% (39/64)\n",
            "1 3 Epoch: 21 | ANN: trainLoss: 0.9924 | trainAcc: 56.2500% (72/128)\n",
            "2 3 Epoch: 21 | ANN: trainLoss: 0.9450 | trainAcc: 59.3023% (102/172)\n",
            "0 2 Epoch: 21 | ANN: testLoss: 1.1879 | testAcc: 32.8125% (21/64)\n",
            "1 2 Epoch: 21 | ANN: testLoss: 1.1830 | testAcc: 39.6552% (46/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 22 | ANN: trainLoss: 0.9421 | trainAcc: 56.2500% (36/64)\n",
            "1 3 Epoch: 22 | ANN: trainLoss: 0.9914 | trainAcc: 53.1250% (68/128)\n",
            "2 3 Epoch: 22 | ANN: trainLoss: 0.9894 | trainAcc: 54.0698% (93/172)\n",
            "0 2 Epoch: 22 | ANN: testLoss: 1.2442 | testAcc: 37.5000% (24/64)\n",
            "1 2 Epoch: 22 | ANN: testLoss: 1.2079 | testAcc: 39.6552% (46/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 23 | ANN: trainLoss: 0.9967 | trainAcc: 56.2500% (36/64)\n",
            "1 3 Epoch: 23 | ANN: trainLoss: 0.9866 | trainAcc: 54.6875% (70/128)\n",
            "2 3 Epoch: 23 | ANN: trainLoss: 0.9442 | trainAcc: 53.4884% (92/172)\n",
            "0 2 Epoch: 23 | ANN: testLoss: 1.1327 | testAcc: 43.7500% (28/64)\n",
            "1 2 Epoch: 23 | ANN: testLoss: 1.1863 | testAcc: 39.6552% (46/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 24 | ANN: trainLoss: 0.9543 | trainAcc: 51.5625% (33/64)\n",
            "1 3 Epoch: 24 | ANN: trainLoss: 0.9562 | trainAcc: 54.6875% (70/128)\n",
            "2 3 Epoch: 24 | ANN: trainLoss: 0.9501 | trainAcc: 54.6512% (94/172)\n",
            "0 2 Epoch: 24 | ANN: testLoss: 1.0737 | testAcc: 45.3125% (29/64)\n",
            "1 2 Epoch: 24 | ANN: testLoss: 1.1521 | testAcc: 41.3793% (48/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 25 | ANN: trainLoss: 0.9307 | trainAcc: 62.5000% (40/64)\n",
            "1 3 Epoch: 25 | ANN: trainLoss: 0.9795 | trainAcc: 56.2500% (72/128)\n",
            "2 3 Epoch: 25 | ANN: trainLoss: 0.9823 | trainAcc: 56.3953% (97/172)\n",
            "0 2 Epoch: 25 | ANN: testLoss: 1.0825 | testAcc: 43.7500% (28/64)\n",
            "1 2 Epoch: 25 | ANN: testLoss: 1.1472 | testAcc: 40.5172% (47/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 26 | ANN: trainLoss: 0.9374 | trainAcc: 57.8125% (37/64)\n",
            "1 3 Epoch: 26 | ANN: trainLoss: 0.9848 | trainAcc: 58.5938% (75/128)\n",
            "2 3 Epoch: 26 | ANN: trainLoss: 0.9334 | trainAcc: 59.8837% (103/172)\n",
            "0 2 Epoch: 26 | ANN: testLoss: 1.1433 | testAcc: 35.9375% (23/64)\n",
            "1 2 Epoch: 26 | ANN: testLoss: 1.1484 | testAcc: 40.5172% (47/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 27 | ANN: trainLoss: 0.8895 | trainAcc: 60.9375% (39/64)\n",
            "1 3 Epoch: 27 | ANN: trainLoss: 0.8990 | trainAcc: 60.9375% (78/128)\n",
            "2 3 Epoch: 27 | ANN: trainLoss: 0.9233 | trainAcc: 58.7209% (101/172)\n",
            "0 2 Epoch: 27 | ANN: testLoss: 1.2649 | testAcc: 37.5000% (24/64)\n",
            "1 2 Epoch: 27 | ANN: testLoss: 1.2042 | testAcc: 37.9310% (44/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 28 | ANN: trainLoss: 0.7889 | trainAcc: 65.6250% (42/64)\n",
            "1 3 Epoch: 28 | ANN: trainLoss: 0.8148 | trainAcc: 67.1875% (86/128)\n",
            "2 3 Epoch: 28 | ANN: trainLoss: 0.8315 | trainAcc: 65.6977% (113/172)\n",
            "0 2 Epoch: 28 | ANN: testLoss: 1.2608 | testAcc: 35.9375% (23/64)\n",
            "1 2 Epoch: 28 | ANN: testLoss: 1.2738 | testAcc: 36.2069% (42/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 29 | ANN: trainLoss: 0.8543 | trainAcc: 64.0625% (41/64)\n",
            "1 3 Epoch: 29 | ANN: trainLoss: 0.8524 | trainAcc: 63.2812% (81/128)\n",
            "2 3 Epoch: 29 | ANN: trainLoss: 0.8718 | trainAcc: 61.0465% (105/172)\n",
            "0 2 Epoch: 29 | ANN: testLoss: 1.2441 | testAcc: 29.6875% (19/64)\n",
            "1 2 Epoch: 29 | ANN: testLoss: 1.2450 | testAcc: 33.6207% (39/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 30 | ANN: trainLoss: 0.8724 | trainAcc: 59.3750% (38/64)\n",
            "1 3 Epoch: 30 | ANN: trainLoss: 0.8734 | trainAcc: 61.7188% (79/128)\n",
            "2 3 Epoch: 30 | ANN: trainLoss: 0.8478 | trainAcc: 61.0465% (105/172)\n",
            "0 2 Epoch: 30 | ANN: testLoss: 1.0977 | testAcc: 40.6250% (26/64)\n",
            "1 2 Epoch: 30 | ANN: testLoss: 1.1755 | testAcc: 37.0690% (43/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 31 | ANN: trainLoss: 0.8520 | trainAcc: 56.2500% (36/64)\n",
            "1 3 Epoch: 31 | ANN: trainLoss: 0.8535 | trainAcc: 57.8125% (74/128)\n",
            "2 3 Epoch: 31 | ANN: trainLoss: 0.8411 | trainAcc: 58.1395% (100/172)\n",
            "0 2 Epoch: 31 | ANN: testLoss: 1.0862 | testAcc: 40.6250% (26/64)\n",
            "1 2 Epoch: 31 | ANN: testLoss: 1.1123 | testAcc: 40.5172% (47/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 32 | ANN: trainLoss: 0.8046 | trainAcc: 68.7500% (44/64)\n",
            "1 3 Epoch: 32 | ANN: trainLoss: 0.8128 | trainAcc: 66.4062% (85/128)\n",
            "2 3 Epoch: 32 | ANN: trainLoss: 0.8320 | trainAcc: 64.5349% (111/172)\n",
            "0 2 Epoch: 32 | ANN: testLoss: 1.1247 | testAcc: 37.5000% (24/64)\n",
            "1 2 Epoch: 32 | ANN: testLoss: 1.0550 | testAcc: 40.5172% (47/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 33 | ANN: trainLoss: 0.8131 | trainAcc: 62.5000% (40/64)\n",
            "1 3 Epoch: 33 | ANN: trainLoss: 0.7894 | trainAcc: 66.4062% (85/128)\n",
            "2 3 Epoch: 33 | ANN: trainLoss: 0.7670 | trainAcc: 66.2791% (114/172)\n",
            "0 2 Epoch: 33 | ANN: testLoss: 0.9546 | testAcc: 48.4375% (31/64)\n",
            "1 2 Epoch: 33 | ANN: testLoss: 1.0611 | testAcc: 43.1034% (50/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 34 | ANN: trainLoss: 0.7485 | trainAcc: 65.6250% (42/64)\n",
            "1 3 Epoch: 34 | ANN: trainLoss: 0.7506 | trainAcc: 66.4062% (85/128)\n",
            "2 3 Epoch: 34 | ANN: trainLoss: 0.7667 | trainAcc: 66.2791% (114/172)\n",
            "0 2 Epoch: 34 | ANN: testLoss: 1.0731 | testAcc: 40.6250% (26/64)\n",
            "1 2 Epoch: 34 | ANN: testLoss: 1.0055 | testAcc: 45.6897% (53/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 35 | ANN: trainLoss: 0.6456 | trainAcc: 75.0000% (48/64)\n",
            "1 3 Epoch: 35 | ANN: trainLoss: 0.6223 | trainAcc: 75.0000% (96/128)\n",
            "2 3 Epoch: 35 | ANN: trainLoss: 0.6923 | trainAcc: 73.8372% (127/172)\n",
            "0 2 Epoch: 35 | ANN: testLoss: 0.9859 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 35 | ANN: testLoss: 1.0250 | testAcc: 49.1379% (57/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 36 | ANN: trainLoss: 0.7466 | trainAcc: 62.5000% (40/64)\n",
            "1 3 Epoch: 36 | ANN: trainLoss: 0.7042 | trainAcc: 65.6250% (84/128)\n",
            "2 3 Epoch: 36 | ANN: trainLoss: 0.7480 | trainAcc: 65.1163% (112/172)\n",
            "0 2 Epoch: 36 | ANN: testLoss: 1.0770 | testAcc: 46.8750% (30/64)\n",
            "1 2 Epoch: 36 | ANN: testLoss: 1.0228 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 37 | ANN: trainLoss: 0.8035 | trainAcc: 60.9375% (39/64)\n",
            "1 3 Epoch: 37 | ANN: trainLoss: 0.7637 | trainAcc: 65.6250% (84/128)\n",
            "2 3 Epoch: 37 | ANN: trainLoss: 0.7400 | trainAcc: 67.4419% (116/172)\n",
            "0 2 Epoch: 37 | ANN: testLoss: 0.9637 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 37 | ANN: testLoss: 1.0375 | testAcc: 48.2759% (56/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 38 | ANN: trainLoss: 0.8017 | trainAcc: 60.9375% (39/64)\n",
            "1 3 Epoch: 38 | ANN: trainLoss: 0.7150 | trainAcc: 65.6250% (84/128)\n",
            "2 3 Epoch: 38 | ANN: trainLoss: 0.7349 | trainAcc: 65.1163% (112/172)\n",
            "0 2 Epoch: 38 | ANN: testLoss: 1.0140 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 38 | ANN: testLoss: 1.0296 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 39 | ANN: trainLoss: 0.7037 | trainAcc: 67.1875% (43/64)\n",
            "1 3 Epoch: 39 | ANN: trainLoss: 0.6822 | trainAcc: 73.4375% (94/128)\n",
            "2 3 Epoch: 39 | ANN: trainLoss: 0.6835 | trainAcc: 72.6744% (125/172)\n",
            "0 2 Epoch: 39 | ANN: testLoss: 0.9678 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 39 | ANN: testLoss: 1.0172 | testAcc: 48.2759% (56/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 40 | ANN: trainLoss: 0.7092 | trainAcc: 67.1875% (43/64)\n",
            "1 3 Epoch: 40 | ANN: trainLoss: 0.7003 | trainAcc: 68.7500% (88/128)\n",
            "2 3 Epoch: 40 | ANN: trainLoss: 0.7024 | trainAcc: 69.1860% (119/172)\n",
            "0 2 Epoch: 40 | ANN: testLoss: 0.9486 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 40 | ANN: testLoss: 0.9834 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 41 | ANN: trainLoss: 0.6646 | trainAcc: 71.8750% (46/64)\n",
            "1 3 Epoch: 41 | ANN: trainLoss: 0.6477 | trainAcc: 70.3125% (90/128)\n",
            "2 3 Epoch: 41 | ANN: trainLoss: 0.6304 | trainAcc: 72.0930% (124/172)\n",
            "0 2 Epoch: 41 | ANN: testLoss: 0.9403 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 41 | ANN: testLoss: 0.9654 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 42 | ANN: trainLoss: 0.5191 | trainAcc: 85.9375% (55/64)\n",
            "1 3 Epoch: 42 | ANN: trainLoss: 0.6207 | trainAcc: 78.1250% (100/128)\n",
            "2 3 Epoch: 42 | ANN: trainLoss: 0.6757 | trainAcc: 73.8372% (127/172)\n",
            "0 2 Epoch: 42 | ANN: testLoss: 1.0037 | testAcc: 43.7500% (28/64)\n",
            "1 2 Epoch: 42 | ANN: testLoss: 0.9320 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 43 | ANN: trainLoss: 0.5689 | trainAcc: 78.1250% (50/64)\n",
            "1 3 Epoch: 43 | ANN: trainLoss: 0.6284 | trainAcc: 71.8750% (92/128)\n",
            "2 3 Epoch: 43 | ANN: trainLoss: 0.6474 | trainAcc: 72.6744% (125/172)\n",
            "0 2 Epoch: 43 | ANN: testLoss: 0.9306 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 43 | ANN: testLoss: 0.9563 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 44 | ANN: trainLoss: 0.8313 | trainAcc: 62.5000% (40/64)\n",
            "1 3 Epoch: 44 | ANN: trainLoss: 0.7051 | trainAcc: 69.5312% (89/128)\n",
            "2 3 Epoch: 44 | ANN: trainLoss: 0.6968 | trainAcc: 70.3488% (121/172)\n",
            "0 2 Epoch: 44 | ANN: testLoss: 0.9994 | testAcc: 48.4375% (31/64)\n",
            "1 2 Epoch: 44 | ANN: testLoss: 0.9371 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 45 | ANN: trainLoss: 0.6205 | trainAcc: 70.3125% (45/64)\n",
            "1 3 Epoch: 45 | ANN: trainLoss: 0.6219 | trainAcc: 73.4375% (94/128)\n",
            "2 3 Epoch: 45 | ANN: trainLoss: 0.6143 | trainAcc: 73.2558% (126/172)\n",
            "0 2 Epoch: 45 | ANN: testLoss: 0.9635 | testAcc: 46.8750% (30/64)\n",
            "1 2 Epoch: 45 | ANN: testLoss: 0.9683 | testAcc: 48.2759% (56/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 46 | ANN: trainLoss: 0.6741 | trainAcc: 71.8750% (46/64)\n",
            "1 3 Epoch: 46 | ANN: trainLoss: 0.5890 | trainAcc: 75.0000% (96/128)\n",
            "2 3 Epoch: 46 | ANN: trainLoss: 0.5781 | trainAcc: 74.4186% (128/172)\n",
            "0 2 Epoch: 46 | ANN: testLoss: 0.9735 | testAcc: 45.3125% (29/64)\n",
            "1 2 Epoch: 46 | ANN: testLoss: 1.0045 | testAcc: 49.1379% (57/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 47 | ANN: trainLoss: 0.6372 | trainAcc: 71.8750% (46/64)\n",
            "1 3 Epoch: 47 | ANN: trainLoss: 0.5937 | trainAcc: 75.0000% (96/128)\n",
            "2 3 Epoch: 47 | ANN: trainLoss: 0.6137 | trainAcc: 73.2558% (126/172)\n",
            "0 2 Epoch: 47 | ANN: testLoss: 1.0320 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 47 | ANN: testLoss: 0.9795 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 48 | ANN: trainLoss: 0.6839 | trainAcc: 73.4375% (47/64)\n",
            "1 3 Epoch: 48 | ANN: trainLoss: 0.6462 | trainAcc: 71.8750% (92/128)\n",
            "2 3 Epoch: 48 | ANN: trainLoss: 0.6424 | trainAcc: 71.5116% (123/172)\n",
            "0 2 Epoch: 48 | ANN: testLoss: 1.0039 | testAcc: 48.4375% (31/64)\n",
            "1 2 Epoch: 48 | ANN: testLoss: 1.0050 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 49 | ANN: trainLoss: 0.4922 | trainAcc: 79.6875% (51/64)\n",
            "1 3 Epoch: 49 | ANN: trainLoss: 0.4944 | trainAcc: 80.4688% (103/128)\n",
            "2 3 Epoch: 49 | ANN: trainLoss: 0.5186 | trainAcc: 79.6512% (137/172)\n",
            "0 2 Epoch: 49 | ANN: testLoss: 0.9970 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 49 | ANN: testLoss: 0.9754 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 50 | ANN: trainLoss: 0.5931 | trainAcc: 73.4375% (47/64)\n",
            "1 3 Epoch: 50 | ANN: trainLoss: 0.5447 | trainAcc: 76.5625% (98/128)\n",
            "2 3 Epoch: 50 | ANN: trainLoss: 0.5522 | trainAcc: 75.5814% (130/172)\n",
            "0 2 Epoch: 50 | ANN: testLoss: 0.9923 | testAcc: 57.8125% (37/64)\n",
            "1 2 Epoch: 50 | ANN: testLoss: 0.9673 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 51 | ANN: trainLoss: 0.6040 | trainAcc: 71.8750% (46/64)\n",
            "1 3 Epoch: 51 | ANN: trainLoss: 0.5835 | trainAcc: 76.5625% (98/128)\n",
            "2 3 Epoch: 51 | ANN: trainLoss: 0.5628 | trainAcc: 76.7442% (132/172)\n",
            "0 2 Epoch: 51 | ANN: testLoss: 0.9594 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 51 | ANN: testLoss: 0.9561 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 52 | ANN: trainLoss: 0.5710 | trainAcc: 76.5625% (49/64)\n",
            "1 3 Epoch: 52 | ANN: trainLoss: 0.5129 | trainAcc: 78.1250% (100/128)\n",
            "2 3 Epoch: 52 | ANN: trainLoss: 0.5355 | trainAcc: 77.3256% (133/172)\n",
            "0 2 Epoch: 52 | ANN: testLoss: 0.9472 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 52 | ANN: testLoss: 0.9853 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 53 | ANN: trainLoss: 0.5294 | trainAcc: 79.6875% (51/64)\n",
            "1 3 Epoch: 53 | ANN: trainLoss: 0.5155 | trainAcc: 79.6875% (102/128)\n",
            "2 3 Epoch: 53 | ANN: trainLoss: 0.5189 | trainAcc: 79.0698% (136/172)\n",
            "0 2 Epoch: 53 | ANN: testLoss: 0.8510 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 53 | ANN: testLoss: 1.0465 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 54 | ANN: trainLoss: 0.5218 | trainAcc: 81.2500% (52/64)\n",
            "1 3 Epoch: 54 | ANN: trainLoss: 0.5259 | trainAcc: 82.8125% (106/128)\n",
            "2 3 Epoch: 54 | ANN: trainLoss: 0.5221 | trainAcc: 81.3953% (140/172)\n",
            "0 2 Epoch: 54 | ANN: testLoss: 1.0926 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 54 | ANN: testLoss: 1.1515 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 55 | ANN: trainLoss: 0.4763 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 55 | ANN: trainLoss: 0.4872 | trainAcc: 82.0312% (105/128)\n",
            "2 3 Epoch: 55 | ANN: trainLoss: 0.5050 | trainAcc: 80.2326% (138/172)\n",
            "0 2 Epoch: 55 | ANN: testLoss: 1.1769 | testAcc: 45.3125% (29/64)\n",
            "1 2 Epoch: 55 | ANN: testLoss: 1.0812 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 56 | ANN: trainLoss: 0.4914 | trainAcc: 78.1250% (50/64)\n",
            "1 3 Epoch: 56 | ANN: trainLoss: 0.4828 | trainAcc: 79.6875% (102/128)\n",
            "2 3 Epoch: 56 | ANN: trainLoss: 0.5050 | trainAcc: 77.3256% (133/172)\n",
            "0 2 Epoch: 56 | ANN: testLoss: 1.0402 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 56 | ANN: testLoss: 0.9909 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 57 | ANN: trainLoss: 0.5645 | trainAcc: 78.1250% (50/64)\n",
            "1 3 Epoch: 57 | ANN: trainLoss: 0.5377 | trainAcc: 77.3438% (99/128)\n",
            "2 3 Epoch: 57 | ANN: trainLoss: 0.5185 | trainAcc: 76.1628% (131/172)\n",
            "0 2 Epoch: 57 | ANN: testLoss: 1.0388 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 57 | ANN: testLoss: 0.9486 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 58 | ANN: trainLoss: 0.4301 | trainAcc: 81.2500% (52/64)\n",
            "1 3 Epoch: 58 | ANN: trainLoss: 0.5204 | trainAcc: 77.3438% (99/128)\n",
            "2 3 Epoch: 58 | ANN: trainLoss: 0.4685 | trainAcc: 81.3953% (140/172)\n",
            "0 2 Epoch: 58 | ANN: testLoss: 1.0729 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 58 | ANN: testLoss: 0.9539 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 59 | ANN: trainLoss: 0.6086 | trainAcc: 70.3125% (45/64)\n",
            "1 3 Epoch: 59 | ANN: trainLoss: 0.5955 | trainAcc: 73.4375% (94/128)\n",
            "2 3 Epoch: 59 | ANN: trainLoss: 0.5488 | trainAcc: 75.5814% (130/172)\n",
            "0 2 Epoch: 59 | ANN: testLoss: 0.9198 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 59 | ANN: testLoss: 0.9979 | testAcc: 49.1379% (57/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 60 | ANN: trainLoss: 0.5317 | trainAcc: 70.3125% (45/64)\n",
            "1 3 Epoch: 60 | ANN: trainLoss: 0.5113 | trainAcc: 76.5625% (98/128)\n",
            "2 3 Epoch: 60 | ANN: trainLoss: 0.4462 | trainAcc: 80.8140% (139/172)\n",
            "0 2 Epoch: 60 | ANN: testLoss: 0.9646 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 60 | ANN: testLoss: 0.9915 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 61 | ANN: trainLoss: 0.6060 | trainAcc: 71.8750% (46/64)\n",
            "1 3 Epoch: 61 | ANN: trainLoss: 0.5228 | trainAcc: 78.1250% (100/128)\n",
            "2 3 Epoch: 61 | ANN: trainLoss: 0.5293 | trainAcc: 77.9070% (134/172)\n",
            "0 2 Epoch: 61 | ANN: testLoss: 0.9498 | testAcc: 46.8750% (30/64)\n",
            "1 2 Epoch: 61 | ANN: testLoss: 1.0060 | testAcc: 48.2759% (56/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 62 | ANN: trainLoss: 0.4978 | trainAcc: 81.2500% (52/64)\n",
            "1 3 Epoch: 62 | ANN: trainLoss: 0.4858 | trainAcc: 79.6875% (102/128)\n",
            "2 3 Epoch: 62 | ANN: trainLoss: 0.4918 | trainAcc: 79.0698% (136/172)\n",
            "0 2 Epoch: 62 | ANN: testLoss: 0.9719 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 62 | ANN: testLoss: 0.9782 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 63 | ANN: trainLoss: 0.4051 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 63 | ANN: trainLoss: 0.4295 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 63 | ANN: trainLoss: 0.4191 | trainAcc: 86.6279% (149/172)\n",
            "0 2 Epoch: 63 | ANN: testLoss: 1.0864 | testAcc: 46.8750% (30/64)\n",
            "1 2 Epoch: 63 | ANN: testLoss: 0.9445 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 64 | ANN: trainLoss: 0.4701 | trainAcc: 78.1250% (50/64)\n",
            "1 3 Epoch: 64 | ANN: trainLoss: 0.4281 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 64 | ANN: trainLoss: 0.4738 | trainAcc: 81.3953% (140/172)\n",
            "0 2 Epoch: 64 | ANN: testLoss: 0.9286 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 64 | ANN: testLoss: 0.9577 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 65 | ANN: trainLoss: 0.5989 | trainAcc: 75.0000% (48/64)\n",
            "1 3 Epoch: 65 | ANN: trainLoss: 0.5270 | trainAcc: 78.1250% (100/128)\n",
            "2 3 Epoch: 65 | ANN: trainLoss: 0.4887 | trainAcc: 79.6512% (137/172)\n",
            "0 2 Epoch: 65 | ANN: testLoss: 0.9261 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 65 | ANN: testLoss: 0.9631 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 66 | ANN: trainLoss: 0.4502 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 66 | ANN: trainLoss: 0.4109 | trainAcc: 88.2812% (113/128)\n",
            "2 3 Epoch: 66 | ANN: trainLoss: 0.3967 | trainAcc: 88.3721% (152/172)\n",
            "0 2 Epoch: 66 | ANN: testLoss: 0.8649 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 66 | ANN: testLoss: 0.9888 | testAcc: 49.1379% (57/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 67 | ANN: trainLoss: 0.4095 | trainAcc: 89.0625% (57/64)\n",
            "1 3 Epoch: 67 | ANN: trainLoss: 0.4764 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 67 | ANN: trainLoss: 0.4697 | trainAcc: 82.5581% (142/172)\n",
            "0 2 Epoch: 67 | ANN: testLoss: 1.0427 | testAcc: 42.1875% (27/64)\n",
            "1 2 Epoch: 67 | ANN: testLoss: 0.9450 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 68 | ANN: trainLoss: 0.5025 | trainAcc: 79.6875% (51/64)\n",
            "1 3 Epoch: 68 | ANN: trainLoss: 0.4588 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 68 | ANN: trainLoss: 0.4635 | trainAcc: 81.9767% (141/172)\n",
            "0 2 Epoch: 68 | ANN: testLoss: 0.9923 | testAcc: 45.3125% (29/64)\n",
            "1 2 Epoch: 68 | ANN: testLoss: 0.9445 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 69 | ANN: trainLoss: 0.3957 | trainAcc: 85.9375% (55/64)\n",
            "1 3 Epoch: 69 | ANN: trainLoss: 0.4123 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 69 | ANN: trainLoss: 0.4207 | trainAcc: 84.3023% (145/172)\n",
            "0 2 Epoch: 69 | ANN: testLoss: 1.1024 | testAcc: 43.7500% (28/64)\n",
            "1 2 Epoch: 69 | ANN: testLoss: 0.9394 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 70 | ANN: trainLoss: 0.4531 | trainAcc: 78.1250% (50/64)\n",
            "1 3 Epoch: 70 | ANN: trainLoss: 0.3922 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 70 | ANN: trainLoss: 0.4008 | trainAcc: 83.1395% (143/172)\n",
            "0 2 Epoch: 70 | ANN: testLoss: 1.0512 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 70 | ANN: testLoss: 0.9545 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 71 | ANN: trainLoss: 0.4135 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 71 | ANN: trainLoss: 0.4357 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 71 | ANN: trainLoss: 0.4218 | trainAcc: 83.7209% (144/172)\n",
            "0 2 Epoch: 71 | ANN: testLoss: 0.9637 | testAcc: 56.2500% (36/64)\n",
            "1 2 Epoch: 71 | ANN: testLoss: 0.9758 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 72 | ANN: trainLoss: 0.4606 | trainAcc: 79.6875% (51/64)\n",
            "1 3 Epoch: 72 | ANN: trainLoss: 0.4391 | trainAcc: 82.0312% (105/128)\n",
            "2 3 Epoch: 72 | ANN: trainLoss: 0.3989 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 72 | ANN: testLoss: 0.9211 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 72 | ANN: testLoss: 0.9769 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 73 | ANN: trainLoss: 0.4235 | trainAcc: 89.0625% (57/64)\n",
            "1 3 Epoch: 73 | ANN: trainLoss: 0.4705 | trainAcc: 82.0312% (105/128)\n",
            "2 3 Epoch: 73 | ANN: trainLoss: 0.4482 | trainAcc: 83.1395% (143/172)\n",
            "0 2 Epoch: 73 | ANN: testLoss: 1.0270 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 73 | ANN: testLoss: 0.9736 | testAcc: 52.5862% (61/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 74 | ANN: trainLoss: 0.4212 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 74 | ANN: trainLoss: 0.3934 | trainAcc: 85.1562% (109/128)\n",
            "2 3 Epoch: 74 | ANN: trainLoss: 0.3926 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 74 | ANN: testLoss: 1.0467 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 74 | ANN: testLoss: 0.9696 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 75 | ANN: trainLoss: 0.4115 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 75 | ANN: trainLoss: 0.4546 | trainAcc: 82.0312% (105/128)\n",
            "2 3 Epoch: 75 | ANN: trainLoss: 0.4502 | trainAcc: 83.1395% (143/172)\n",
            "0 2 Epoch: 75 | ANN: testLoss: 1.0008 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 75 | ANN: testLoss: 0.9564 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 76 | ANN: trainLoss: 0.4245 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 76 | ANN: trainLoss: 0.4175 | trainAcc: 85.1562% (109/128)\n",
            "2 3 Epoch: 76 | ANN: trainLoss: 0.4044 | trainAcc: 84.8837% (146/172)\n",
            "0 2 Epoch: 76 | ANN: testLoss: 0.9542 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 76 | ANN: testLoss: 0.9432 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 77 | ANN: trainLoss: 0.3682 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 77 | ANN: trainLoss: 0.3899 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 77 | ANN: trainLoss: 0.3945 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 77 | ANN: testLoss: 0.9343 | testAcc: 57.8125% (37/64)\n",
            "1 2 Epoch: 77 | ANN: testLoss: 0.9421 | testAcc: 55.1724% (64/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 78 | ANN: trainLoss: 0.3509 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 78 | ANN: trainLoss: 0.3671 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 78 | ANN: trainLoss: 0.3742 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 78 | ANN: testLoss: 1.0128 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 78 | ANN: testLoss: 0.9350 | testAcc: 55.1724% (64/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 79 | ANN: trainLoss: 0.4109 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 79 | ANN: trainLoss: 0.3851 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 79 | ANN: trainLoss: 0.3652 | trainAcc: 86.0465% (148/172)\n",
            "0 2 Epoch: 79 | ANN: testLoss: 0.9355 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 79 | ANN: testLoss: 0.9487 | testAcc: 55.1724% (64/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 80 | ANN: trainLoss: 0.3364 | trainAcc: 92.1875% (59/64)\n",
            "1 3 Epoch: 80 | ANN: trainLoss: 0.3943 | trainAcc: 87.5000% (112/128)\n",
            "2 3 Epoch: 80 | ANN: trainLoss: 0.3695 | trainAcc: 87.2093% (150/172)\n",
            "0 2 Epoch: 80 | ANN: testLoss: 1.0144 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 80 | ANN: testLoss: 0.9505 | testAcc: 55.1724% (64/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 81 | ANN: trainLoss: 0.3549 | trainAcc: 89.0625% (57/64)\n",
            "1 3 Epoch: 81 | ANN: trainLoss: 0.3731 | trainAcc: 87.5000% (112/128)\n",
            "2 3 Epoch: 81 | ANN: trainLoss: 0.3763 | trainAcc: 87.7907% (151/172)\n",
            "0 2 Epoch: 81 | ANN: testLoss: 0.8513 | testAcc: 60.9375% (39/64)\n",
            "1 2 Epoch: 81 | ANN: testLoss: 0.9765 | testAcc: 56.0345% (65/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 82 | ANN: trainLoss: 0.3469 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 82 | ANN: trainLoss: 0.3556 | trainAcc: 87.5000% (112/128)\n",
            "2 3 Epoch: 82 | ANN: trainLoss: 0.3916 | trainAcc: 86.0465% (148/172)\n",
            "0 2 Epoch: 82 | ANN: testLoss: 0.9527 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 82 | ANN: testLoss: 0.9672 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 83 | ANN: trainLoss: 0.4229 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 83 | ANN: trainLoss: 0.3726 | trainAcc: 89.8438% (115/128)\n",
            "2 3 Epoch: 83 | ANN: trainLoss: 0.3760 | trainAcc: 88.9535% (153/172)\n",
            "0 2 Epoch: 83 | ANN: testLoss: 0.8767 | testAcc: 60.9375% (39/64)\n",
            "1 2 Epoch: 83 | ANN: testLoss: 0.9727 | testAcc: 55.1724% (64/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 84 | ANN: trainLoss: 0.3710 | trainAcc: 90.6250% (58/64)\n",
            "1 3 Epoch: 84 | ANN: trainLoss: 0.3721 | trainAcc: 89.0625% (114/128)\n",
            "2 3 Epoch: 84 | ANN: trainLoss: 0.3789 | trainAcc: 90.1163% (155/172)\n",
            "0 2 Epoch: 84 | ANN: testLoss: 0.9274 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 84 | ANN: testLoss: 0.9691 | testAcc: 56.0345% (65/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 85 | ANN: trainLoss: 0.3529 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 85 | ANN: trainLoss: 0.3723 | trainAcc: 85.1562% (109/128)\n",
            "2 3 Epoch: 85 | ANN: trainLoss: 0.3766 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 85 | ANN: testLoss: 0.8600 | testAcc: 56.2500% (36/64)\n",
            "1 2 Epoch: 85 | ANN: testLoss: 0.9790 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 86 | ANN: trainLoss: 0.3495 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 86 | ANN: trainLoss: 0.3905 | trainAcc: 85.1562% (109/128)\n",
            "2 3 Epoch: 86 | ANN: trainLoss: 0.3655 | trainAcc: 86.0465% (148/172)\n",
            "0 2 Epoch: 86 | ANN: testLoss: 1.0016 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 86 | ANN: testLoss: 0.9681 | testAcc: 53.4483% (62/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 87 | ANN: trainLoss: 0.3556 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 87 | ANN: trainLoss: 0.3668 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 87 | ANN: trainLoss: 0.3650 | trainAcc: 88.3721% (152/172)\n",
            "0 2 Epoch: 87 | ANN: testLoss: 0.9895 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 87 | ANN: testLoss: 0.9756 | testAcc: 50.0000% (58/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 88 | ANN: trainLoss: 0.3561 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 88 | ANN: trainLoss: 0.3766 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 88 | ANN: trainLoss: 0.4103 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 88 | ANN: testLoss: 0.9744 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 88 | ANN: testLoss: 0.9762 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 89 | ANN: trainLoss: 0.3972 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 89 | ANN: trainLoss: 0.4069 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 89 | ANN: trainLoss: 0.3735 | trainAcc: 84.8837% (146/172)\n",
            "0 2 Epoch: 89 | ANN: testLoss: 0.9578 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 89 | ANN: testLoss: 0.9724 | testAcc: 50.8621% (59/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 90 | ANN: trainLoss: 0.3999 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 90 | ANN: trainLoss: 0.3617 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 90 | ANN: trainLoss: 0.3674 | trainAcc: 87.2093% (150/172)\n",
            "0 2 Epoch: 90 | ANN: testLoss: 0.9651 | testAcc: 48.4375% (31/64)\n",
            "1 2 Epoch: 90 | ANN: testLoss: 0.9700 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 91 | ANN: trainLoss: 0.3279 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 91 | ANN: trainLoss: 0.3844 | trainAcc: 87.5000% (112/128)\n",
            "2 3 Epoch: 91 | ANN: trainLoss: 0.4084 | trainAcc: 86.0465% (148/172)\n",
            "0 2 Epoch: 91 | ANN: testLoss: 1.0877 | testAcc: 40.6250% (26/64)\n",
            "1 2 Epoch: 91 | ANN: testLoss: 0.9542 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 92 | ANN: trainLoss: 0.4512 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 92 | ANN: trainLoss: 0.4091 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 92 | ANN: trainLoss: 0.4060 | trainAcc: 83.7209% (144/172)\n",
            "0 2 Epoch: 92 | ANN: testLoss: 0.9482 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 92 | ANN: testLoss: 0.9689 | testAcc: 51.7241% (60/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 93 | ANN: trainLoss: 0.4551 | trainAcc: 85.9375% (55/64)\n",
            "1 3 Epoch: 93 | ANN: trainLoss: 0.3872 | trainAcc: 88.2812% (113/128)\n",
            "2 3 Epoch: 93 | ANN: trainLoss: 0.3763 | trainAcc: 89.5349% (154/172)\n",
            "0 2 Epoch: 93 | ANN: testLoss: 1.0159 | testAcc: 59.3750% (38/64)\n",
            "1 2 Epoch: 93 | ANN: testLoss: 0.9602 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 94 | ANN: trainLoss: 0.3545 | trainAcc: 87.5000% (56/64)\n",
            "1 3 Epoch: 94 | ANN: trainLoss: 0.3653 | trainAcc: 85.1562% (109/128)\n",
            "2 3 Epoch: 94 | ANN: trainLoss: 0.3691 | trainAcc: 84.8837% (146/172)\n",
            "0 2 Epoch: 94 | ANN: testLoss: 1.0282 | testAcc: 57.8125% (37/64)\n",
            "1 2 Epoch: 94 | ANN: testLoss: 0.9549 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 95 | ANN: trainLoss: 0.3857 | trainAcc: 85.9375% (55/64)\n",
            "1 3 Epoch: 95 | ANN: trainLoss: 0.3910 | trainAcc: 85.9375% (110/128)\n",
            "2 3 Epoch: 95 | ANN: trainLoss: 0.4066 | trainAcc: 84.3023% (145/172)\n",
            "0 2 Epoch: 95 | ANN: testLoss: 0.8642 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 95 | ANN: testLoss: 0.9728 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 96 | ANN: trainLoss: 0.3841 | trainAcc: 90.6250% (58/64)\n",
            "1 3 Epoch: 96 | ANN: trainLoss: 0.3746 | trainAcc: 86.7188% (111/128)\n",
            "2 3 Epoch: 96 | ANN: trainLoss: 0.4060 | trainAcc: 87.2093% (150/172)\n",
            "0 2 Epoch: 96 | ANN: testLoss: 0.9532 | testAcc: 54.6875% (35/64)\n",
            "1 2 Epoch: 96 | ANN: testLoss: 0.9595 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 97 | ANN: trainLoss: 0.3865 | trainAcc: 84.3750% (54/64)\n",
            "1 3 Epoch: 97 | ANN: trainLoss: 0.3869 | trainAcc: 84.3750% (108/128)\n",
            "2 3 Epoch: 97 | ANN: trainLoss: 0.4275 | trainAcc: 83.1395% (143/172)\n",
            "0 2 Epoch: 97 | ANN: testLoss: 1.0228 | testAcc: 50.0000% (32/64)\n",
            "1 2 Epoch: 97 | ANN: testLoss: 0.9534 | testAcc: 54.3103% (63/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 98 | ANN: trainLoss: 0.3112 | trainAcc: 92.1875% (59/64)\n",
            "1 3 Epoch: 98 | ANN: trainLoss: 0.3322 | trainAcc: 89.0625% (114/128)\n",
            "2 3 Epoch: 98 | ANN: trainLoss: 0.3430 | trainAcc: 87.7907% (151/172)\n",
            "0 2 Epoch: 98 | ANN: testLoss: 0.9549 | testAcc: 51.5625% (33/64)\n",
            "1 2 Epoch: 98 | ANN: testLoss: 0.9634 | testAcc: 53.4483% (62/116)\n",
            "\n",
            "\n",
            "0 3 Epoch: 99 | ANN: trainLoss: 0.4465 | trainAcc: 82.8125% (53/64)\n",
            "1 3 Epoch: 99 | ANN: trainLoss: 0.3824 | trainAcc: 83.5938% (107/128)\n",
            "2 3 Epoch: 99 | ANN: trainLoss: 0.3872 | trainAcc: 85.4651% (147/172)\n",
            "0 2 Epoch: 99 | ANN: testLoss: 1.0647 | testAcc: 53.1250% (34/64)\n",
            "1 2 Epoch: 99 | ANN: testLoss: 0.9484 | testAcc: 54.3103% (63/116)\n",
            "---------------------------------------------\n",
            "Converting using MaxNorm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.40it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 10.09it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "ANN accuracy: Test: 54.3100%\n",
            "SNN accuracy: max_norm: 53.4483%\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "An example for the pipeline pf ANN to SNN Conversion Framework.\n",
        "\"\"\"\n",
        "\n",
        "def framework_pipeline(train_x, train_y, test_x, test_y, epoch=200, batch=64, T=100):\n",
        "    \"\"\"\n",
        "        ANN to SNN Conversion framework\n",
        "    input:\n",
        "        train_x, test_x (float): Train and test data, shape as: samples*length*ch (samples*ch*length).\n",
        "        train_y, test_y (int): Train and test label, shape as: samples, ie.: [0, 1, 1, 0, ..., 2].\n",
        "        epoch (int): Total train and test epoch\n",
        "        batch (int): Batch size\n",
        "        T (int): Time step for SNN\n",
        "    output:\n",
        "        None\n",
        "    \"\"\"\n",
        "    ann_model = LENet(classes_num=4).to(device)\n",
        "    ann_model.apply(initialize_weights)\n",
        "\n",
        "    train_acc, test_acc, model_trained = train_ann(ann_model, train_x, train_y, test_x, test_y, ep=epoch, batch=batch)\n",
        "    max_norm_acc = anntosnn(model_trained, train_x, train_y, test_x, test_y, batch=batch, T=T)\n",
        "    snn_model = ann2snn.Converter(mode='max', dataloader=data_loader(train_x, train_y, batch=batch))(model_trained)\n",
        "\n",
        "    # Get ANN predictions\n",
        "    ann_model.eval()\n",
        "    ann_predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader(test_x, test_y, batch=batch, shuffle=False, drop=False):\n",
        "            outputs = ann_model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            ann_predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Get SNN predictions\n",
        "    snn_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader(test_x, test_y, batch=batch, shuffle=False, drop=False):\n",
        "          for m in snn_model.modules():\n",
        "              if hasattr(m, 'reset'):\n",
        "                  m.reset()\n",
        "          for t in range(T):\n",
        "              if t == 0:\n",
        "                  outputs = snn_model(inputs)\n",
        "              else:\n",
        "                  outputs += snn_model(inputs)\n",
        "          _, predicted = outputs.max(1)\n",
        "          snn_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "    # Confusion Matrix for ANN\n",
        "    cm_ann = confusion_matrix(true_labels, ann_predictions)\n",
        "    disp_ann = ConfusionMatrixDisplay(confusion_matrix=cm_ann)\n",
        "    disp_ann.plot()\n",
        "    plt.title('Confusion Matrix - ANN')\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix for SNN\n",
        "    cm_snn = confusion_matrix(true_labels, snn_predictions)\n",
        "    disp_snn = ConfusionMatrixDisplay(confusion_matrix=cm_snn)\n",
        "    disp_snn.plot()\n",
        "    plt.title('Confusion Matrix - SNN')\n",
        "    plt.show()\n",
        "\n",
        "    print('\\n')\n",
        "    print('ANN accuracy: Test: %.4f%%' % (test_acc * 100))\n",
        "    print('SNN accuracy: max_norm: %.4f%%' % (max_norm_acc[-1] * 100))\n",
        "\n",
        "\n",
        "# Getting real samples\n",
        "\n",
        "#Locally load the dataset\n",
        "file = scio.loadmat('Datasets\\BCICIV_2a_gdf\\Derivatives\\A07T.mat')\n",
        "\n",
        "# Google Colab load the dataset\n",
        "# file = scio.loadmat('/content/A01T.mat')\n",
        "all_data = file['all_data']\n",
        "all_label = file['all_label']\n",
        "\n",
        "datasetX = torch.tensor(all_data, dtype=torch.float32)\n",
        "datasetY = torch.tensor(all_label, dtype=torch.int64)\n",
        "train_data, test_data, train_label, test_label = train_test_split(datasetX, datasetY, test_size=0.4, shuffle=True,\n",
        "                                                                  random_state=0)\n",
        "\n",
        "# ANN to SNN Conversion\n",
        "framework_pipeline(train_data, train_label, test_data, test_label, epoch=100, batch=64, T=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o4VT4r0r-xf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
